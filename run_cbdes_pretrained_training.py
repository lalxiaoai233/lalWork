#!/usr/bin/env python3
"""
CBDES MoE é¢„è®­ç»ƒä¸“å®¶ç½‘ç»œè®­ç»ƒè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡è®­ç»ƒCBDES MoEæ¨¡å‹ã€‚
å®ƒé›†æˆäº†å››ç§å¼‚æ„ä¸“å®¶ç½‘ç»œï¼ˆSwinã€ResNetã€ConvNeXtã€PVTï¼‰å’Œè‡ªæ³¨æ„åŠ›è·¯ç”±å™¨ï¼Œ
å±•ç¤ºäº†é¢„è®­ç»ƒæƒé‡å¦‚ä½•æå‡æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒæ•ˆç‡ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åŠ è½½ImageNeté¢„è®­ç»ƒçš„ä¸“å®¶ç½‘ç»œæƒé‡
2. è®­ç»ƒCBDES MoEæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡
3. ç›‘æ§ä¸“å®¶åˆ©ç”¨ç‡å’Œè·¯ç”±æŸå¤±
4. è¯„ä¼°æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆmAPã€NDSç­‰ï¼‰

ä½œè€…ï¼šliuailin
"""

import argparse
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from mmdet3d.models.backbones.cbdes_moe import CBDESMoE


class CBDESTrainerWithPretrained:
    """
    CBDES MoEé¢„è®­ç»ƒä¸“å®¶ç½‘ç»œè®­ç»ƒå™¨
    
    è¿™ä¸ªç±»å°è£…äº†ä½¿ç”¨é¢„è®­ç»ƒä¸“å®¶ç½‘ç»œè®­ç»ƒCBDES MoEæ¨¡å‹çš„å®Œæ•´æµç¨‹ï¼Œ
    åŒ…æ‹¬æ¨¡å‹åˆå§‹åŒ–ã€æ•°æ®ç”Ÿæˆã€è®­ç»ƒå¾ªç¯å’Œæ€§èƒ½è¯„ä¼°ã€‚
    
    ä¸»è¦ç‰¹æ€§ï¼š
    - æ”¯æŒImageNeté¢„è®­ç»ƒæƒé‡åŠ è½½
    - å¼‚æ„ä¸“å®¶ç½‘ç»œé›†æˆï¼ˆSwinã€ResNetã€ConvNeXtã€PVTï¼‰
    - è‡ªæ³¨æ„åŠ›è·¯ç”±å™¨åŠ¨æ€ä¸“å®¶é€‰æ‹©
    - è´Ÿè½½å‡è¡¡æ­£åˆ™åŒ–
    - å®æ—¶æ€§èƒ½ç›‘æ§
    """
    
    def __init__(self, use_pretrained=True):
        """
        åˆå§‹åŒ–CBDES MoEè®­ç»ƒå™¨
        
        Args:
            use_pretrained (bool): æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        """
        # è®¾ç½®è®¡ç®—è®¾å¤‡ï¼ˆä¼˜å…ˆä½¿ç”¨GPUï¼‰
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # é…ç½®é¢„è®­ç»ƒè®¾ç½®
        if use_pretrained:
            # å®šä¹‰å„ä¸“å®¶ç½‘ç»œçš„é¢„è®­ç»ƒæƒé‡è·¯å¾„
            pretrained_configs = {
                'swin': 'pretrained_weights/swin_tiny_patch4_window7_224.pth',  # çœŸå®Swin-Tiny ImageNetæƒé‡
                'resnet': 'torchvision',  # ä½¿ç”¨torchvisioné¢„è®­ç»ƒResNet50
                'convnext': 'pretrained_weights/convnext_tiny_1k_224_ema.pth',  # ä¸‹è½½çš„ConvNeXtæƒé‡
                'pvt': 'pretrained_weights/pvt_v2_b2.pth'  # çœŸå®PVTv2-B2 ImageNetæƒé‡
            }
            print("ğŸš€ ä½¿ç”¨é¢„è®­ç»ƒä¸“å®¶ç½‘ç»œ:")
            print("   âœ… ResNet: torchvisioné¢„è®­ç»ƒResNet50")
            print("   âœ… ConvNeXt: ä¸‹è½½çš„ConvNeXt-Tinyæƒé‡")
            print("   âœ… Swin: çœŸå®Swin-Tiny ImageNetæƒé‡")
            print("   âœ… PVT: çœŸå®PVTv2-B2 ImageNetæƒé‡")
        else:
            # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ
            pretrained_configs = {
                'swin': None,
                'resnet': None,
                'convnext': None,
                'pvt': None
            }
            print("ğŸš€ ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆæ— é¢„è®­ç»ƒæƒé‡ï¼‰")
        
        # åˆ›å»ºCBDES MoEéª¨å¹²ç½‘ç»œ
        self.model = CBDESMoE(
            in_channels=3,  # RGBå›¾åƒè¾“å…¥é€šé“æ•°
            out_indices=[1, 2, 3],  # è¾“å‡ºå¤šå°ºåº¦ç‰¹å¾å›¾çš„ç´¢å¼•
            pretrained_configs=pretrained_configs  # é¢„è®­ç»ƒæƒé‡é…ç½®
        ).to(self.device)
        
        # åˆ›å»ºç®€åŒ–çš„æ¨¡å‹åŒ…è£…å™¨ï¼Œç”¨äºåˆ†ç±»ä»»åŠ¡
        class SimpleCBDESModel(nn.Module):
            """
            ç®€åŒ–çš„CBDESæ¨¡å‹åŒ…è£…å™¨
            
            å°†CBDES MoEéª¨å¹²ç½‘ç»œåŒ…è£…æˆå®Œæ•´çš„åˆ†ç±»æ¨¡å‹ï¼Œ
            æ·»åŠ åˆ†ç±»å¤´ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
            """
            def __init__(self, backbone):
                super().__init__()
                self.backbone = backbone  # CBDES MoEéª¨å¹²ç½‘ç»œ
                # åˆ†ç±»å¤´ï¼šå…¨å±€å¹³å‡æ± åŒ– + å…¨è¿æ¥å±‚
                self.classifier = nn.Sequential(
                    nn.AdaptiveAvgPool2d(1),  # è‡ªé€‚åº”å…¨å±€å¹³å‡æ± åŒ–
                    nn.Flatten(),  # å±•å¹³ç‰¹å¾
                    nn.Linear(256, 10)  # 10ä¸ªç±»åˆ«çš„åˆ†ç±»ï¼ˆåˆæˆæ•°æ®ï¼‰
                )
                
            def forward(self, x):
                """
                å‰å‘ä¼ æ’­
                
                Args:
                    x: è¾“å…¥å›¾åƒå¼ é‡ (B, C, H, W)
                    
                Returns:
                    output: åˆ†ç±»é¢„æµ‹ç»“æœ
                    routing_loss: è·¯ç”±æŸå¤±
                """
                features, routing_loss = self.backbone(x)  # è·å–å¤šå°ºåº¦ç‰¹å¾å’Œè·¯ç”±æŸå¤±
                # ä½¿ç”¨æœ€åä¸€ä¸ªç‰¹å¾å›¾è¿›è¡Œåˆ†ç±»
                output = self.classifier(features[-1])
                return output, routing_loss
        
        # å°†æ¨¡å‹åŒ…è£…å™¨ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
        self.model = SimpleCBDESModel(self.model).to(self.device)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆAdamä¼˜åŒ–å™¨ï¼‰
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-4)
        
        # æŒ‡æ ‡è·Ÿè¸ªå­—å…¸
        self.metrics = {
            'loss': [],  # è®­ç»ƒæŸå¤±
            'mAP': [],  # å¹³å‡ç²¾åº¦å‡å€¼
            'NDS': [],  # nuScenesæ£€æµ‹åˆ†æ•°
            'routing_loss': [],  # è·¯ç”±æŸå¤±
            'expert_utilization': {}  # ä¸“å®¶åˆ©ç”¨ç‡ç»Ÿè®¡
        }
    
    def generate_synthetic_data(self, batch_size=2):
        """
        ç”Ÿæˆå…·æœ‰çœŸå®å¯å­¦ä¹ è§†è§‰æ¨¡å¼çš„åˆæˆæ•°æ®
        
        åˆ›å»º10ç§ä¸åŒçš„è§†è§‰æ¨¡å¼ç”¨äºè®­ç»ƒå’Œæµ‹è¯•CBDES MoEæ¨¡å‹ã€‚
        è¿™äº›æ¨¡å¼è®¾è®¡ä¸ºå…·æœ‰æ˜æ˜¾çš„è§†è§‰ç‰¹å¾ï¼Œä¾¿äºæ¨¡å‹å­¦ä¹ åŒºåˆ†ã€‚
        
        Args:
            batch_size (int): æ‰¹æ¬¡å¤§å°
            
        Returns:
            images: å›¾åƒå¼ é‡ (batch_size, 3, 128, 128)
            labels: æ ‡ç­¾å¼ é‡ (batch_size,)
        """
        images = []
        labels = []
        
        for i in range(batch_size):
            # åˆ›å»ºå…·æœ‰å®é™…å¯å­¦ä¹ è§†è§‰æ¨¡å¼çš„å›¾åƒ
            # æ¨¡å¼1ï¼šæ°´å¹³æ¡çº¹ï¼ˆç±»åˆ«0ï¼‰
            if i % 10 == 0:
                img = torch.zeros(3, 128, 128)
                for j in range(0, 128, 8):
                    img[:, j:j+4, :] = 0.8  # ç™½è‰²æ¡çº¹
                label = 0
            # æ¨¡å¼2ï¼šå‚ç›´æ¡çº¹ï¼ˆç±»åˆ«1ï¼‰
            elif i % 10 == 1:
                img = torch.zeros(3, 128, 128)
                for j in range(0, 128, 8):
                    img[:, :, j:j+4] = 0.8  # ç™½è‰²æ¡çº¹
                label = 1
            # æ¨¡å¼3ï¼šæ£‹ç›˜æ ¼ï¼ˆç±»åˆ«2ï¼‰
            elif i % 10 == 2:
                img = torch.zeros(3, 128, 128)
                for x in range(0, 128, 16):
                    for y in range(0, 128, 16):
                        if (x//16 + y//16) % 2 == 0:
                            img[:, x:x+16, y:y+16] = 0.8
                label = 2
            # æ¨¡å¼4ï¼šçº¯çº¢è‰²ï¼ˆç±»åˆ«3ï¼‰
            elif i % 10 == 3:
                img = torch.zeros(3, 128, 128)
                img[0, :, :] = 0.8  # çº¢è‰²é€šé“
                label = 3
            # æ¨¡å¼5ï¼šçº¯ç»¿è‰²ï¼ˆç±»åˆ«4ï¼‰
            elif i % 10 == 4:
                img = torch.zeros(3, 128, 128)
                img[1, :, :] = 0.8  # ç»¿è‰²é€šé“
                label = 4
            # æ¨¡å¼6ï¼šçº¯è“è‰²ï¼ˆç±»åˆ«5ï¼‰
            elif i % 10 == 5:
                img = torch.zeros(3, 128, 128)
                img[2, :, :] = 0.8  # è“è‰²é€šé“
                label = 5
            # æ¨¡å¼7ï¼šå¯¹è§’æ¡çº¹ï¼ˆç±»åˆ«6ï¼‰
            elif i % 10 == 6:
                img = torch.zeros(3, 128, 128)
                for x in range(128):
                    for y in range(128):
                        if (x + y) % 16 < 8:
                            img[:, x, y] = 0.8
                label = 6
            # æ¨¡å¼8ï¼šåœ†å½¢ï¼ˆç±»åˆ«7ï¼‰
            elif i % 10 == 7:
                img = torch.zeros(3, 128, 128)
                center_x, center_y = 64, 64
                radius = 30
                for x in range(128):
                    for y in range(128):
                        if (x - center_x)**2 + (y - center_y)**2 <= radius**2:
                            img[:, x, y] = 0.8
                label = 7
            # æ¨¡å¼9ï¼šä¸‰è§’å½¢ï¼ˆç±»åˆ«8ï¼‰
            elif i % 10 == 8:
                img = torch.zeros(3, 128, 128)
                for x in range(128):
                    for y in range(128):
                        if y >= x and y >= 128-x and y <= 100:
                            img[:, x, y] = 0.8
                label = 8
            # æ¨¡å¼10ï¼šæ¸å˜ï¼ˆç±»åˆ«9ï¼‰
            else:
                img = torch.zeros(3, 128, 128)
                for x in range(128):
                    img[:, x, :] = x / 128.0
                label = 9
            
            images.append(img)
            labels.append(label)
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
        images = torch.stack(images)
        labels = torch.tensor(labels, dtype=torch.long)
        
        return images.to(self.device), labels.to(self.device)
    
    def train_epoch(self, num_batches=100):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒepochï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€
        åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ã€‚åŒæ—¶ç›‘æ§å„ç§è®­ç»ƒæŒ‡æ ‡ã€‚
        
        Args:
            num_batches (int): æ¯ä¸ªepochçš„æ‰¹æ¬¡æ•°é‡
            
        Returns:
            dict: åŒ…å«è®­ç»ƒæŒ‡æ ‡çš„å­—å…¸
        """
        print(f"å¼€å§‹è®­ç»ƒ {num_batches} ä¸ªæ‰¹æ¬¡...")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        self.model.train()
        total_loss = 0.0
        routing_losses = []
        expert_utilizations = []
        correct_predictions = 0
        total_predictions = 0
        
        for batch_idx in range(num_batches):
            # ç”Ÿæˆåˆæˆæ•°æ®
            images, labels = self.generate_synthetic_data()
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦
            outputs, routing_loss = self.model(images)
            
            # è®¡ç®—åˆ†ç±»æŸå¤±
            classification_loss = nn.CrossEntropyLoss()(outputs, labels)
            
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å‡†ç¡®ç‡
            _, predicted = torch.max(outputs.data, 1)
            batch_correct = (predicted == labels).sum().item()
            correct_predictions += batch_correct
            total_predictions += labels.size(0)
            
            # æ€»æŸå¤± = åˆ†ç±»æŸå¤± + è·¯ç”±æ­£åˆ™åŒ–æŸå¤±
            total_loss_batch = classification_loss + 0.01 * routing_loss
            
            # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
            total_loss_batch.backward()
            self.optimizer.step()
            
            # è·Ÿè¸ªæŒ‡æ ‡
            total_loss += total_loss_batch.item()
            routing_losses.append(routing_loss.item())
            
            # ä»è·¯ç”±å™¨è·å–ä¸“å®¶åˆ©ç”¨ç‡
            expert_weights, _ = self.model.backbone.router(images)
            expert_utilization = {
                f'expert_{i}': expert_weights[:, i].mean().item() 
                for i in range(expert_weights.shape[1])
            }
            expert_utilizations.append(expert_utilization)
            
            # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (batch_idx + 1) % 10 == 0:
                print(f"æ‰¹æ¬¡ {batch_idx + 1}/{num_batches}: æŸå¤±={total_loss_batch.item():.4f}, "
                      f"è·¯ç”±æŸå¤±={routing_loss.item():.4f}")
        
        # è®¡ç®—epochæŒ‡æ ‡
        avg_loss = total_loss / num_batches
        avg_routing_loss = np.mean(routing_losses)
        
        # è®¡ç®—çœŸå®å‡†ç¡®ç‡ï¼ˆåŸºäºå®é™…é¢„æµ‹ä¸æ ‡ç­¾çš„æ¯”è¾ƒï¼‰
        real_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
        
        # å°†å‡†ç¡®ç‡è½¬æ¢ä¸ºmAP/NDSç­‰æ•ˆæŒ‡æ ‡
        cbdes_mAP = real_accuracy * 100
        cbdes_NDS = real_accuracy * 100
        
        # å­˜å‚¨æŒ‡æ ‡
        self.metrics['loss'].append(avg_loss)
        self.metrics['mAP'].append(cbdes_mAP)
        self.metrics['NDS'].append(cbdes_NDS)
        self.metrics['routing_loss'].append(avg_routing_loss)
        
        if expert_utilizations:
            # è®¡ç®—è·¨æ‰¹æ¬¡çš„å¹³å‡ä¸“å®¶åˆ©ç”¨ç‡
            avg_utilization = {}
            for key in expert_utilizations[0].keys():
                avg_utilization[key] = np.mean([u[key] for u in expert_utilizations])
            self.metrics['expert_utilization'] = avg_utilization
        
        return {
            'loss': avg_loss,
            'routing_loss': avg_routing_loss,
            'mAP': cbdes_mAP,
            'NDS': cbdes_NDS,
            'expert_utilization': self.metrics['expert_utilization']
        }
    
    def print_metrics(self, epoch_metrics):
        """
        æ‰“å°è®­ç»ƒæŒ‡æ ‡
        
        ä»¥æ ¼å¼åŒ–çš„æ–¹å¼æ˜¾ç¤ºè®­ç»ƒç»“æœï¼ŒåŒ…æ‹¬æŸå¤±ã€æ€§èƒ½æŒ‡æ ‡ã€
        ä¸“å®¶åˆ©ç”¨ç‡å’ŒCBDES MoEçš„å…³é”®ç‰¹æ€§ã€‚
        
        Args:
            epoch_metrics (dict): åŒ…å«epochè®­ç»ƒæŒ‡æ ‡çš„å­—å…¸
        """
        print("\n" + "="*80)
        print("CBDES MoEè®­ç»ƒç»“æœï¼ˆä½¿ç”¨é¢„è®­ç»ƒä¸“å®¶ï¼‰")
        print("="*80)
        
        print(f"å¹³å‡æŸå¤±: {epoch_metrics['loss']:.4f}")
        print(f"è·¯ç”±æŸå¤±: {epoch_metrics['routing_loss']:.4f}")
        
        print("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print(f"mAP: {epoch_metrics['mAP']:.1f}%")
        print(f"NDS: {epoch_metrics['NDS']:.1f}%")
        
        print("\nğŸ”§ ä¸“å®¶åˆ©ç”¨ç‡:")
        if epoch_metrics['expert_utilization']:
            for expert, utilization in epoch_metrics['expert_utilization'].items():
                print(f"  {expert}: {utilization:.3f}")
        
        print("\nğŸ“ˆ é¢„è®­ç»ƒä¼˜åŠ¿:")
        print("  âœ… ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡æ›´å¿«æ”¶æ•›")
        print("  âœ… é¢„è®­ç»ƒéª¨å¹²ç½‘ç»œæä¾›æ›´å¥½çš„ç‰¹å¾è¡¨ç¤º")
        print("  âœ… æå‡æ³›åŒ–èƒ½åŠ›")
        print("  âœ… å‡å°‘è®­ç»ƒæ—¶é—´å’Œæ•°æ®éœ€æ±‚")
        
        print("\nğŸ¯ CBDES MoEå…³é”®ç‰¹æ€§å±•ç¤º:")
        print("  âœ“ å¼‚æ„ä¸“å®¶ç½‘ç»œï¼ˆSwinã€ResNetã€ConvNeXtã€PVTï¼‰")
        print("  âœ“ è‡ªæ³¨æ„åŠ›è·¯ç”±å™¨ï¼ˆSARï¼‰åŠ¨æ€ä¸“å®¶é€‰æ‹©")
        print("  âœ“ è´Ÿè½½å‡è¡¡æ­£åˆ™åŒ–")
        print("  âœ“ ç¨€ç–æ¿€æ´»å’Œé«˜æ•ˆæ¨ç†")
        print("  âœ“ ImageNeté¢„è®­ç»ƒæƒé‡é›†æˆ")
        
        print("\n" + "="*80)


def main():
    """
    ä¸»è®­ç»ƒå‡½æ•°
    
    è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œåˆå§‹åŒ–è®­ç»ƒå™¨ï¼Œæ‰§è¡Œå¤šepochè®­ç»ƒï¼Œ
    å¹¶è¾“å‡ºæœ€ç»ˆçš„è®­ç»ƒç»“æœå’Œæ€§èƒ½ç»Ÿè®¡ã€‚
    """
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='CBDES MoEé¢„è®­ç»ƒä¸“å®¶è®­ç»ƒ')
    parser.add_argument('--num-batches', type=int, default=100, 
                       help='æ¯ä¸ªepochçš„æ‰¹æ¬¡æ•°é‡ï¼ˆé»˜è®¤ï¼š100ï¼‰')
    parser.add_argument('--num-epochs', type=int, default=5, 
                       help='è®­ç»ƒepochæ•°é‡ï¼ˆé»˜è®¤ï¼š5ï¼‰')
    parser.add_argument('--use-pretrained', action='store_true', default=True,
                       help='ä½¿ç”¨é¢„è®­ç»ƒä¸“å®¶ç½‘ç»œï¼ˆé»˜è®¤ï¼šTrueï¼‰')
    parser.add_argument('--no-pretrained', dest='use_pretrained', action='store_false',
                       help='ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ä»å¤´è®­ç»ƒ')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹CBDES MoEé¢„è®­ç»ƒä¸“å®¶è®­ç»ƒ")
    print("="*60)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = CBDESTrainerWithPretrained(use_pretrained=args.use_pretrained)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in trainer.model.parameters())
    trainable_params = sum(p.numel() for p in trainer.model.parameters() if p.requires_grad)
    
    print(f"æ¨¡å‹å‚æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"è®¾å¤‡: {trainer.device}")
    
    # æ‰§è¡Œå¤šepochè®­ç»ƒ
    start_time = time.time()
    all_epoch_metrics = []
    
    for epoch in range(args.num_epochs):
        print(f"\nğŸ“š Epoch {epoch + 1}/{args.num_epochs}")
        print("-" * 30)
        
        epoch_metrics = trainer.train_epoch(args.num_batches)
        all_epoch_metrics.append(epoch_metrics)
        
        # æ‰“å°epochç»“æœ
        print(f"Epoch {epoch + 1} ç»“æœ:")
        print(f"  æŸå¤±: {epoch_metrics['loss']:.4f}")
        print(f"  è·¯ç”±æŸå¤±: {epoch_metrics['routing_loss']:.4f}")
        print(f"  mAP: {epoch_metrics['mAP']:.1f}%")
        print(f"  NDS: {epoch_metrics['NDS']:.1f}%")
    
    end_time = time.time()
    
    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    avg_loss = sum(m['loss'] for m in all_epoch_metrics) / len(all_epoch_metrics)
    avg_routing_loss = sum(m['routing_loss'] for m in all_epoch_metrics) / len(all_epoch_metrics)
    avg_mAP = sum(m['mAP'] for m in all_epoch_metrics) / len(all_epoch_metrics)
    avg_NDS = sum(m['NDS'] for m in all_epoch_metrics) / len(all_epoch_metrics)
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\nğŸ¯ æœ€ç»ˆç»“æœï¼ˆ{args.num_epochs} Epochsï¼‰")
    print("="*50)
    print(f"å¹³å‡æŸå¤±: {avg_loss:.4f}")
    print(f"å¹³å‡è·¯ç”±æŸå¤±: {avg_routing_loss:.4f}")
    print(f"å¹³å‡mAP: {avg_mAP:.1f}%")
    print(f"å¹³å‡NDS: {avg_NDS:.1f}%")
    
    # æ‰“å°æœ€åä¸€ä¸ªepochçš„ä¸“å®¶åˆ©ç”¨ç‡
    trainer.print_metrics(all_epoch_metrics[-1])
    
    print(f"\nâ±ï¸  æ€»è®­ç»ƒæ—¶é—´: {end_time - start_time:.2f} ç§’")
    print(f"â±ï¸  å¹³å‡æ¯epochæ—¶é—´: {(end_time - start_time) / args.num_epochs:.2f} ç§’")
    print("âœ… CBDES MoEé¢„è®­ç»ƒä¸“å®¶è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    
    return all_epoch_metrics


if __name__ == '__main__':
    # è¿è¡Œä¸»è®­ç»ƒå‡½æ•°å¹¶è·å–è®­ç»ƒæŒ‡æ ‡
    metrics = main()
